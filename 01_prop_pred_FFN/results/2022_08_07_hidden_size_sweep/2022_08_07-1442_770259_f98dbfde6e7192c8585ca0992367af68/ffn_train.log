2022-08-07 14:43:40,102 INFO: Args:
batch_size: 32
dataset_name: caco
debug: false
dropout: 0.1
gpu: false
hidden_size: 256
layers: 3
max_epochs: 100
num_workers: 1
save_dir: results/2022_08_07_hidden_size_sweep/2022_08_07-1442_770259_f98dbfde6e7192c8585ca0992367af68
seed: 1

2022-08-07 14:43:46,176 INFO: Train, val, test sizes: (637, 91, 182)

  | Name              | Type       | Params
-------------------------------------------------
0 | activation        | ReLU       | 0     
1 | output_activation | Identity   | 0     
2 | mlp               | MLPBlocks  | 656 K 
3 | output_layer      | Sequential | 257   
-------------------------------------------------
656 K     Trainable params
0         Non-trainable params
656 K     Total params
2.626     Total estimated model params size (MB)
2022-08-07 14:43:46,549 INFO: Epoch 0, step 19-- val_loss : 2.58933424949646
2022-08-07 14:43:46,792 INFO: Epoch 1, step 39-- val_loss : 1.8474446535110474
2022-08-07 14:43:46,924 INFO: Epoch 2, step 49-- train_loss : 1.3615612983703613
2022-08-07 14:43:47,026 INFO: Epoch 2, step 59-- val_loss : 1.4714189767837524
2022-08-07 14:43:47,270 INFO: Epoch 3, step 79-- val_loss : 1.2526352405548096
2022-08-07 14:43:47,451 INFO: Epoch 4, step 99-- train_loss : 0.6064863204956055
2022-08-07 14:43:47,509 INFO: Epoch 4, step 99-- val_loss : 1.1595782041549683
2022-08-07 14:43:47,747 INFO: Epoch 5, step 119-- val_loss : 1.1078412532806396
2022-08-07 14:43:47,988 INFO: Epoch 6, step 139-- val_loss : 1.0565234422683716
2022-08-07 14:43:48,133 INFO: Epoch 7, step 149-- train_loss : 0.8461395502090454
2022-08-07 14:43:48,244 INFO: Epoch 7, step 159-- val_loss : 1.034218668937683
2022-08-07 14:43:48,498 INFO: Epoch 8, step 179-- val_loss : 1.0191010236740112
2022-08-07 14:43:48,684 INFO: Epoch 9, step 199-- train_loss : 0.7006665468215942
2022-08-07 14:43:48,739 INFO: Epoch 9, step 199-- val_loss : 1.0180834531784058
2022-08-07 14:43:48,985 INFO: Epoch 10, step 219-- val_loss : 1.0020248889923096
2022-08-07 14:43:49,233 INFO: Epoch 11, step 239-- val_loss : 1.0026150941848755
2022-08-07 14:43:49,362 INFO: Epoch 12, step 249-- train_loss : 0.817177414894104
2022-08-07 14:43:49,468 INFO: Epoch 12, step 259-- val_loss : 0.9921942353248596
2022-08-07 14:43:49,733 INFO: Epoch 13, step 279-- val_loss : 0.994421124458313
2022-08-07 14:43:49,902 INFO: Epoch 14, step 299-- train_loss : 0.614862859249115
2022-08-07 14:43:49,955 INFO: Epoch 14, step 299-- val_loss : 0.9950452446937561
2022-08-07 14:43:50,189 INFO: Epoch 15, step 319-- val_loss : 0.9880827069282532
2022-08-07 14:43:50,427 INFO: Epoch 16, step 339-- val_loss : 0.9897823929786682
2022-08-07 14:43:50,555 INFO: Epoch 17, step 349-- train_loss : 0.9838491678237915
2022-08-07 14:43:50,658 INFO: Epoch 17, step 359-- val_loss : 0.9843793511390686
2022-08-07 14:43:50,906 INFO: Epoch 18, step 379-- val_loss : 0.9830778241157532
2022-08-07 14:43:51,102 INFO: Epoch 19, step 399-- train_loss : 0.392995148897171
2022-08-07 14:43:51,156 INFO: Epoch 19, step 399-- val_loss : 0.9837300777435303
2022-08-07 14:43:51,401 INFO: Epoch 20, step 419-- val_loss : 0.982421875
2022-08-07 14:43:51,634 INFO: Epoch 21, step 439-- val_loss : 0.9804188013076782
2022-08-07 14:43:51,788 INFO: Epoch 22, step 449-- train_loss : 1.0250664949417114
2022-08-07 14:43:51,897 INFO: Epoch 22, step 459-- val_loss : 0.9761921167373657
2022-08-07 14:43:52,144 INFO: Epoch 23, step 479-- val_loss : 0.9774256348609924
2022-08-07 14:43:52,318 INFO: Epoch 24, step 499-- train_loss : 0.8097671866416931
2022-08-07 14:43:52,378 INFO: Epoch 24, step 499-- val_loss : 0.9744157195091248
2022-08-07 14:43:52,627 INFO: Epoch 25, step 519-- val_loss : 0.97723388671875
2022-08-07 14:43:52,860 INFO: Epoch 26, step 539-- val_loss : 0.9761981964111328
2022-08-07 14:43:52,988 INFO: Epoch 27, step 549-- train_loss : 0.9519609808921814
2022-08-07 14:43:53,097 INFO: Epoch 27, step 559-- val_loss : 0.9735762476921082
2022-08-07 14:43:53,348 INFO: Epoch 28, step 579-- val_loss : 0.974403977394104
2022-08-07 14:43:53,522 INFO: Epoch 29, step 599-- train_loss : 1.027387261390686
2022-08-07 14:43:53,582 INFO: Epoch 29, step 599-- val_loss : 0.9686984419822693
2022-08-07 14:43:53,822 INFO: Epoch 30, step 619-- val_loss : 0.9705955386161804
2022-08-07 14:43:54,048 INFO: Epoch 31, step 639-- val_loss : 0.9705391526222229
2022-08-07 14:43:54,175 INFO: Epoch 32, step 649-- train_loss : 0.5892369151115417
2022-08-07 14:43:54,286 INFO: Epoch 32, step 659-- val_loss : 0.9662594795227051
2022-08-07 14:43:54,539 INFO: Epoch 33, step 679-- val_loss : 0.9692050218582153
2022-08-07 14:43:54,712 INFO: Epoch 34, step 699-- train_loss : 0.48075228929519653
2022-08-07 14:43:54,773 INFO: Epoch 34, step 699-- val_loss : 0.9685467481613159
2022-08-07 14:43:55,004 INFO: Epoch 35, step 719-- val_loss : 0.9678511023521423
2022-08-07 14:43:55,227 INFO: Epoch 36, step 739-- val_loss : 0.9644113183021545
2022-08-07 14:43:55,370 INFO: Epoch 37, step 749-- train_loss : 0.663002073764801
2022-08-07 14:43:55,473 INFO: Epoch 37, step 759-- val_loss : 0.9669496417045593
2022-08-07 14:43:55,719 INFO: Epoch 38, step 779-- val_loss : 0.9641326069831848
2022-08-07 14:43:55,913 INFO: Epoch 39, step 799-- train_loss : 0.5616904497146606
2022-08-07 14:43:55,972 INFO: Epoch 39, step 799-- val_loss : 0.9623534083366394
2022-08-07 14:43:56,228 INFO: Epoch 40, step 819-- val_loss : 0.9610558748245239
2022-08-07 14:43:56,481 INFO: Epoch 41, step 839-- val_loss : 0.962516188621521
2022-08-07 14:43:56,607 INFO: Epoch 42, step 849-- train_loss : 0.5173175930976868
2022-08-07 14:43:56,708 INFO: Epoch 42, step 859-- val_loss : 0.9606360793113708
2022-08-07 14:43:56,952 INFO: Epoch 43, step 879-- val_loss : 0.962002694606781
2022-08-07 14:43:57,123 INFO: Epoch 44, step 899-- train_loss : 0.7743424773216248
2022-08-07 14:43:57,182 INFO: Epoch 44, step 899-- val_loss : 0.9576312303543091
2022-08-07 14:43:57,427 INFO: Epoch 45, step 919-- val_loss : 0.9586681127548218
2022-08-07 14:43:57,656 INFO: Epoch 46, step 939-- val_loss : 0.9607393741607666
2022-08-07 14:43:57,778 INFO: Epoch 47, step 949-- train_loss : 0.5875838994979858
2022-08-07 14:43:57,890 INFO: Epoch 47, step 959-- val_loss : 0.961401641368866
2022-08-07 14:43:58,114 INFO: Epoch 48, step 979-- val_loss : 0.9570139050483704
2022-08-07 14:43:58,304 INFO: Epoch 49, step 999-- train_loss : 0.5441149473190308
2022-08-07 14:43:58,364 INFO: Epoch 49, step 999-- val_loss : 0.9559395909309387
2022-08-07 14:43:58,604 INFO: Epoch 50, step 1019-- val_loss : 0.954425036907196
2022-08-07 14:43:58,835 INFO: Epoch 51, step 1039-- val_loss : 0.9575001001358032
2022-08-07 14:43:58,953 INFO: Epoch 52, step 1049-- train_loss : 0.631191611289978
2022-08-07 14:43:59,056 INFO: Epoch 52, step 1059-- val_loss : 0.95452880859375
2022-08-07 14:43:59,282 INFO: Epoch 53, step 1079-- val_loss : 0.9517340064048767
2022-08-07 14:43:59,470 INFO: Epoch 54, step 1099-- train_loss : 0.9299797415733337
2022-08-07 14:43:59,517 INFO: Epoch 54, step 1099-- val_loss : 0.9566906094551086
2022-08-07 14:43:59,748 INFO: Epoch 55, step 1119-- val_loss : 0.9521520137786865
2022-08-07 14:43:59,976 INFO: Epoch 56, step 1139-- val_loss : 0.9495822787284851
2022-08-07 14:44:00,116 INFO: Epoch 57, step 1149-- train_loss : 0.8912632465362549
2022-08-07 14:44:00,228 INFO: Epoch 57, step 1159-- val_loss : 0.9495969414710999
2022-08-07 14:44:00,461 INFO: Epoch 58, step 1179-- val_loss : 0.9537456631660461
2022-08-07 14:44:00,632 INFO: Epoch 59, step 1199-- train_loss : 0.6485745906829834
2022-08-07 14:44:00,693 INFO: Epoch 59, step 1199-- val_loss : 0.9507036209106445
2022-08-07 14:44:00,921 INFO: Epoch 60, step 1219-- val_loss : 0.949342668056488
2022-08-07 14:44:01,153 INFO: Epoch 61, step 1239-- val_loss : 0.9496936202049255
2022-08-07 14:44:01,279 INFO: Epoch 62, step 1249-- train_loss : 1.0856815576553345
2022-08-07 14:44:01,378 INFO: Epoch 62, step 1259-- val_loss : 0.9476653933525085
2022-08-07 14:44:01,611 INFO: Epoch 63, step 1279-- val_loss : 0.9516500234603882
2022-08-07 14:44:01,788 INFO: Epoch 64, step 1299-- train_loss : 0.9474336504936218
2022-08-07 14:44:01,844 INFO: Epoch 64, step 1299-- val_loss : 0.9485324621200562
2022-08-07 14:44:02,078 INFO: Epoch 65, step 1319-- val_loss : 0.9478508830070496
2022-08-07 14:44:02,304 INFO: Epoch 66, step 1339-- val_loss : 0.9489240646362305
2022-08-07 14:44:02,426 INFO: Epoch 67, step 1349-- train_loss : 0.6548521518707275
2022-08-07 14:44:02,533 INFO: Epoch 67, step 1359-- val_loss : 0.9472722411155701
2022-08-07 14:44:02,779 INFO: Epoch 68, step 1379-- val_loss : 0.9466342926025391
2022-08-07 14:44:02,966 INFO: Epoch 69, step 1399-- train_loss : 0.7488095164299011
2022-08-07 14:44:03,018 INFO: Epoch 69, step 1399-- val_loss : 0.9434734582901001
2022-08-07 14:44:03,268 INFO: Epoch 70, step 1419-- val_loss : 0.9461249113082886
2022-08-07 14:44:03,495 INFO: Epoch 71, step 1439-- val_loss : 0.9489308595657349
2022-08-07 14:44:03,620 INFO: Epoch 72, step 1449-- train_loss : 0.8264926671981812
2022-08-07 14:44:03,726 INFO: Epoch 72, step 1459-- val_loss : 0.9467587471008301
2022-08-07 14:44:03,952 INFO: Epoch 73, step 1479-- val_loss : 0.9510077834129333
2022-08-07 14:44:04,132 INFO: Epoch 74, step 1499-- train_loss : 0.7468438148498535
2022-08-07 14:44:04,191 INFO: Epoch 74, step 1499-- val_loss : 0.9444594383239746
2022-08-07 14:44:04,427 INFO: Epoch 75, step 1519-- val_loss : 0.9450586438179016
2022-08-07 14:44:04,650 INFO: Epoch 76, step 1539-- val_loss : 0.9452634453773499
2022-08-07 14:44:04,778 INFO: Epoch 77, step 1549-- train_loss : 0.5944312810897827
2022-08-07 14:44:04,881 INFO: Epoch 77, step 1559-- val_loss : 0.9457912445068359
2022-08-07 14:44:05,106 INFO: Epoch 78, step 1579-- val_loss : 0.9447525143623352
2022-08-07 14:44:05,282 INFO: Epoch 79, step 1599-- train_loss : 0.5141145586967468
2022-08-07 14:44:05,332 INFO: Epoch 79, step 1599-- val_loss : 0.9466115832328796
2022-08-07 14:44:05,343 INFO: Loaded model with from /home/samlg/projects/dl-chem-101/01_prop_pred_FFN/results/2022_08_07_hidden_size_sweep/2022_08_07-1442_770259_f98dbfde6e7192c8585ca0992367af68/version_0/epoch=69-val_loss=0.94.ckpt with val loss of 0.9434734582901001
2022-08-07 14:44:05,407 INFO: Epoch 79, step 1600-- test_loss : 1.276263952255249
2022-08-07 14:44:05,409 INFO: Program finished in: 25.30822443962097 seconds
